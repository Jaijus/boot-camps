{
 "metadata": {
  "name": "data_analysis_and_exploration"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Data exploration and analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After learning some of the basics of scientific computing with python, we should now be ready to tackle some real data. In the following example, we will learn how to read data from file, how to build a rudimentary analysis of the data and how to modularize it into functions. We will talk briefly about profiling functions, before moving on. In the following segment, we will look at organizing these components into a reproducible workflow.\n",
      "\n",
      "**Note** : This is a typical workflow. Learn the parameters of your problem in an interactive environment and then scale it up in a non-interactive mode "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, a couple of words about the data we will use. For the examples we will look at here, we will look at data taken from electrophysiological experiments conducted on the grasshopper `Locusta Migratoria`. These grasshoppers use acoustic communication as part of their courtship process. This means that hearing is an exremely important sense for them. The grasshoppers hear through ears located near the base of their hind-legs. A tympanal membrane transforms acoustic air-vibrations into mechanical stimuli, which are transduced into electrical signals in the cell bodies of approximately 70 auditory receptor cells located in the ears on each side. \n",
      "\n",
      "These receptor cells generate action potentials, which travel down the axons of these cells to a sensory ganglion located in the meta-thoracic segment of the grasshopper body. The information is further processed there and affects the behavior of the animal. \n",
      "\n",
      "In the following example, we will look at intra-cellular data recorded using sharp electrodes from the axons of these auditory receptor cells. The data was stored as the times relative to the beginning of the experiment at which a spike was detected in the voltage trace of the recording. In addition, we also have the stimulus that was presented, stored as voltage values that were sent to the speakers. Using these two bits of information we will calculate the spike-triggered average stimulus (or STA). This is often used as a way to characterize the filter properties of the cell.\n",
      "\n",
      "The full data set is available do download on the [CRCNS website](crcns.org). More details about this data can be found in [this paper](http://arokem.org/publications/papers/Rokem2006InfoJiitter.pdf)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Getting the data. \n",
      "\n",
      "Let's start by getting the data. I have placed a zip file with the data we will need in this link: http://arokem.org/data/grasshoppers.zip\n",
      "\n",
      "Let's copy the data to the same location as this notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls  # This is the same one we use in the bash shell"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the notebooks and `.md` files in this directory, you should now also see these files: \n",
      "    \n",
      "    grasshopper_spike_times1.txt       \n",
      "    grasshopper_spike_times2.txt\n",
      "    grasshopper_stimulus1.txt\n",
      "    grasshopper_stimulus2.txt\n",
      "\n",
      "There are several different types of data-files you might encounter: \n",
      "    \n",
      "- Text files (such as these) are easy to read using one of the following: \n",
      "    \n",
      "        file\n",
      "    \n",
      "        np.loadtxt\n",
      "        \n",
      "- A special case of text files are csv files. These can be read using the above methods or using\n",
      "\n",
      "        mlab.csv2rec\n",
      "\n",
      "  We'll demonstrate that in just a bit\n",
      "\n",
      "- Binary file formats. These kinds of files are useful, because they can be used to store large amounts of data in a structured manner. But these include a variety of specialized formats. To read these, you will often require some knowledge about the structure and contents of the file. In particular, neuroimaging data is a binary file format that can be a headache to deal with. Fortunately, the excellent `nibabel` library knows how to deal with many of these files. To deal with dicom files (yet another bff...), you can use `pydicom`\n",
      "\n",
      "- Files from Matlab. Since many of you use matlab, you might encounter mat-files on a regular basis. I will just mention that there are several options for handling those files. For some mat files, you can use the `scipy.io` module, which contains `loadmat' and `savemat` functions. Another option is the more complicated PyTables library, which supports the HDF5 file format (which is used in some versions of Matlab).\n",
      "\n",
      "\n",
      "Let's start by looking at the most generic form of file i/o: "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Using `file` objects\n",
      "\n",
      "We start by using the python [`file` class](http://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files). Calling the built-in `open` returns a `file` class instance (object). The first input to this function is a string containing the path to the file (relative or absolute). The second input is the mode in which the file is opened: `'r'` designates 'read', `'w'` designates 'write' and `'a'` designates 'append'. In this case, we only want to read the file (not change it!):  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We open a file, and get back a file object:\n",
      "f_st_1 = open('grasshopper_spike_times1.txt', 'r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a look at the object you got and its methods. \n",
      "\n",
      "\n",
      "One method that seems useful is the `read` method. Let's call it  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use the read method:\n",
      "r = f_st_1.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What did we get back? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To examine what something is, you can use `type`\n",
      "type(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take a look:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Look at it's representation\n",
      "r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What if we ask python to `print` it?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Printing isn't always the same as representing it:\n",
      "print(r)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you open the file with a text editor, you'll see that this is also the way the editor will parse the file. That is, the newline characters (`\\n`) get parsed as a carriage return (think type-writer...). \n",
      "\n",
      "The content of this file is a header segment (the lines starting with `#`) and a data segment. The header information will be important because we want to know what intensity of stimulus was used for this cell (that's the line `# intensity (dB): 76.4286`)\n",
      "\n",
      "\n",
      "The data in integers, below the header information are spike times during one trial, given in micro-seconds. Just by looking at these numbers, can you infer what the sampling rate was? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How would we go about converting the string we got into numbers we can use to analyze (preferably packaged in a `numpy array`)? Maybe we can use the `file`'s `readline` method and parse the data line-by-line? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use readline\n",
      "f_st_1.readline()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What happened there? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It turns out that the `file` object has a state: it keeps track of the point to which it has most recently read. Since we previously used `read`, which reads in the entire file, we are at the end of it now. Let's use `seek` to get back to the beginning of the file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To reset the state of the file to point to the beginning of the file, use `seek`: \n",
      "f_st_1.seek(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: take a look at the docstring for `seek`. It takes as input a byte count from a given point in the file. 0 is the very beginning of the file. If we use `tell` to assess that we can see that: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To assess where you are, use `tell`\n",
      "f_st_1.tell()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's use `readline` again:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# When we next use readline, we get the first line of the file:\n",
      "line = f_st_1.readline()\n",
      "line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That gives us the very first line in the file. Where are we now? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calling tell again gives us another number:\n",
      "f_st_1.tell()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where did that number come from? Any guesses? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Maybe it's related to this?\n",
      "len(line) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One reasonable guess at this point would be that there is a one-to-one mapping between bytes into the file and characters in the string. This may become a bit more tricky if you are trying to read other formats of data, but for now, let's just leave it at that. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise: make an `array` reading the file with `readline`. \n",
      "\n",
      "### Important : we don't want to include the lines that begin with `#` in our array, only the spike times! "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here's my version of this: \n",
      "\n",
      "f_st_1.seek(0) # Go to the beginning of the file \n",
      "lines = []\n",
      "line = f_st_1.readline()\n",
      "\n",
      "while line != '': \n",
      "    if line[0] != '#': \n",
      "        lines.append(int(line))\n",
      "    line = f_st_1.readline()\n",
      "    \n",
      "spike_array = np.array(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What just happened? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's look at what we have there\n",
      "line"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data can have unexpected features, which is why it is beneficial to explore it in an interactive environment that allows probing and prodding it. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's fix the problem with the above piece of code: \n",
      "f_st_1.seek(0) # Go to the beginning of the file \n",
      "lines = []\n",
      "line = f_st_1.readline()\n",
      "\n",
      "while line != '': \n",
      "    if line[0] != '#' and line != '\\n':  # The more you know...\n",
      "        lines.append(int(line))\n",
      "    line = f_st_1.readline()\n",
      "    \n",
      "spike_array = np.array(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can display what we got:\n",
      "plot(spike_array,'.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What does this tell us about the firing rate of this cell? What do you think the duration of the trial was?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It turns out that there is another option that will do this more elegantly for us. Enter `readlines`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use readlines to get all the lines in the file\n",
      "f_st_1.seek(0)\n",
      "lines = f_st_1.readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take a look at it:\n",
      "lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `readlines` method returns a list of strings. This is something that we can iterate over."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Revise our file-reading routine:\n",
      "\n",
      "f_st_1.seek(0) # Go to the beginning of the file \n",
      "lines = []\n",
      "\n",
      "for line in f_st_1.readlines():\n",
      "    if line[0] != '#' and line != '\\n':\n",
      "        lines.append(int(line))\n",
      "    line = f_st_1.readline()\n",
      "    \n",
      "spike_array = np.array(lines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A short aside about list comprehensions. \n",
      "\n",
      "[List comprehensions](http://docs.python.org/2/tutorial/datastructures.html#list-comprehensions) are one of the most elegant constructs in Python (consistently voted for \"favorite feature of the language\" by nerds everywhere). It can be a bit confusing on first blush, but once you start using them, it can become addictive. \n",
      "\n",
      "Here's how it works: you can construct a list by surrounding an iteration with square brackets. For example, this: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [] \n",
      "for x in range(10):\n",
      "    a.append(x**2)\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "is equivalent to this: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [x**2 for x in range(10)]\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also embed a logical statement in there for selection: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Only square the non-zero even elements:\n",
      "a = [x**2 for x in range(10) if x>0 and np.mod(x,2)==0]\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Back to our readlines function from above. How would you generate the spike-time array using a list comprehension?\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here's what the file-reading routine looks like with a list comprehension\n",
      "f_st_1.seek(0)\n",
      "# The following is equivalent to the above loop + call to array\n",
      "spike_array = np.array([int(l) for l in f_st_1.readlines() if l[0] != '#' and l != '\\n']) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# As a sanity check, plot the array you got. Does it look the same as before?\n",
      "plot(spike_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Before moving on, it is generally a good idea to close open files when you are done with them: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calling the `close` method closes the file cleanly:\n",
      "f_st_1.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Knowing how to deal with text files is quite useful. \n",
      "\n",
      "Having now learned that, let me now reveal to you that as I hinted before, `numpy` actually has a function that will do all of this for us:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use `loadtxt` instead of what you did above:\n",
      "spike_array = np.loadtxt('grasshopper_spike_times1.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It even knows not to read the comment lines and to ignore empty lines.\n",
      "\n",
      "Consider that when you generate your own data files. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot it as a sanity check\n",
      "plot(spike_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Actually `loadtxt` is quite a bit more sophisticated than our little loop:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We can look at the file, just to convince ourselves that it's doing much more than what we did:\n",
      "np.loadtxt??"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise : write a function that will take as input the file-name and returns: \n",
      "\n",
      "### 1. A numpy array with the spike times\n",
      "### 2. A dictionary with the header information \n",
      "\n",
      "It should do something like: \n",
      "    \n",
      "    spikes, header = get_data(fname)\n",
      "    \n",
      "Where `spikes` is the array and `header` is the dict with header information "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define a function that does these things:\n",
      "def get_data(fname): \n",
      "    \"\"\" \n",
      "    Read spike time data and header information from file\n",
      "\n",
      "    Parameters \n",
      "    ----------\n",
      "    fname : str\n",
      "        Path to the file \n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    spikes : 1-d array\n",
      "        Contains the spike times in the order they were \n",
      "        recorded in the file\n",
      "    \n",
      "    header : dict\n",
      "        Header information from the data file\n",
      "    \"\"\"\n",
      "    f = open(fname, 'r')\n",
      "    header = {}\n",
      "    l = f.readline()\n",
      "    while l.startswith('#'):  # Same as l[0]=='#' \n",
      "        line_parts = l.split(':')\n",
      "        # We split the key again, so that we don't get the '#'\n",
      "        header[line_parts[0].split('# ')[-1]] = line_parts[1]\n",
      "        l = f.readline()\n",
      "\n",
      "    f.close()\n",
      "    spikes = np.loadtxt(fname)\n",
      "    \n",
      "    return spikes, header\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spikes, header = get_data('grasshopper_spike_times1.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the header value fields are all strings now, but that doesn't make sense for most of these. However, they can't all be cast to floating point numbers, so we'll need to do something clever:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data(fname): \n",
      "    \"\"\" \n",
      "    Read spike time data and header information from file\n",
      "\n",
      "    Parameters \n",
      "    ----------\n",
      "    fname : str\n",
      "        Path to the file \n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    spikes : 1-d array\n",
      "        Contains the spike times in the order they were \n",
      "        recorded in the file\n",
      "    \n",
      "    header : dict\n",
      "        Header information from the data file\n",
      "    \"\"\"\n",
      "    f = open(fname, 'r')\n",
      "    header = {}\n",
      "    l = f.readline()\n",
      "    while l.startswith('#'):  # Same as l[0]=='#' \n",
      "        line_parts = l.split(':')\n",
      "        # We split the key again, so that we don't get the '#'\n",
      "        try:\n",
      "            header[line_parts[0].split('# ')[-1]] = float(line_parts[1])\n",
      "        except:\n",
      "            header[line_parts[0].split('# ')[-1]] = line_parts[1]\n",
      "        l = f.readline()\n",
      "    \n",
      "    spikes = np.loadtxt(fname)\n",
      "    f.close()\n",
      "    return spikes, header\n",
      "        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spikes, header = get_data('grasshopper_spike_times1.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "header "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Let's recap what we've seen so far: \n",
      "\n",
      "- We've acquainted ourselves with the `file` class instance. \n",
      "- We took a little interlude to appreciate the beauty of list comprehensions\n",
      "- We've learned how to use `np.loadtxt`\n",
      "- We wrote a script to read spike-time data and header information\n",
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Next, let's consider the stimulus files\n",
      "\n",
      "Let's take a look: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open('grasshopper_stimulus1.txt')\n",
      "print f.read()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This file contains two columns delimited by two spaces. The first designates a time-bin during the experiment (at 20 kHz) and the other is the voltage passed to the experimental equipment to produce a sound pressure wave from the speakers. \n",
      "\n",
      "From reading the documentation on the CRCNS wesbite, you can learn that the transformation between voltage and dB SPL is rather straight-forward: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def volt2dB(volt, max_dB):\n",
      "    \"\"\" \n",
      "    Convert from voltage to dB SPL\n",
      "\n",
      "    Parameters \n",
      "    ----------\n",
      "    volt : 1d array\n",
      "        The stimulus in volts \n",
      "    \n",
      "    max_dB : int or float \n",
      "        The maximal dB value presented in the experiment\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    `max_dB` can be gleaned from the header information, see `get_data`\n",
      "    \"\"\"\n",
      "    stim = 20  * (np.log10(volt / 2.0e-5))\n",
      "    return max_dB - stim.max() + stim\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To read the file, we will use a function called csv2rec."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlab.csv2rec?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes a file name as input and returns a so-called `recarray`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rec_arr = mlab.csv2rec('grasshopper_stimulus1.txt', delimiter=' ', names = ['time', 'volt'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To understand the difference between a `recarray` and a standard `numpy` `array`, let's look at some of the salient differences between them: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.array([1,2,3,4,5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(a)\n",
      "print(rec_arr)\n",
      "print(a.dtype)\n",
      "print(rec_arr.dtype)\n",
      "print(a.shape)\n",
      "print(rec_arr.shape)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main differences are that: \n",
      "\n",
      "- Items in the `recarray` are all tuples\n",
      "- The dtype is a compound dtype made out of `(name, format)` tuples\n",
      "- The shape of the `recarray` indicates that it only has one dimension"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's make a nice plot of the stimulus\n",
      "\n",
      "To do this, we will use the plotting API of matplotlib. This API lives in a namespace that is called 'matplotlib.pyplot'. Per convention, this namespace is imported in pylab under the name `plt`. The logic behind this is quite different from the matlab-style plotting style, but it's worth learning, because it gives you a lot of fine-grained control over your plotting and visualization in matplotlib. \n",
      "\n",
      "One of the most useful functions in this name-space is `subplots`. This gives you back handles to `Figure` and `AxisSubPlot` objects, which can do a lot of different things. The most "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure, axis = plt.subplots(1)\n",
      "axis.plot(rec_arr['time'], rec_arr['volt'])\n",
      "axis.set_xlabel(r'Time ($\\mu$sec)')\n",
      "axis.set_ylabel('Amplitude (V)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(figure)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the functions we have already created to display the same stimulus in dB SPL instead:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figure, axis = plt.subplots(1)\n",
      "# Convert to dB using the function we defined above: \n",
      "in_dB = volt2dB(rec_arr['volt'], header['intensity (dB)'])\n",
      "# Then display:\n",
      "axis.plot(rec_arr['time'], in_dB) \n",
      "axis.set_xlabel(r'Time ($\\mu$sec)')\n",
      "axis.set_ylabel('Amplitude (dB SPL)')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Analysis - computing the STA\n",
      "\n",
      "Next, we would like to compute the spike-triggered average stimulus (or STA). This characterizes the sensitivity of the cell to different stimuli.\n",
      "\n",
      "To do that, we need to average all the segments of the stimulus that preced spike times.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Let's brain-storm : how would you go about doing this? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are two general strategies we could take to this: \n",
      "    \n",
      "- One is to loop over our spikes and keep adding the stimuli that precede each one. This is relatively time-demanding. \n",
      "\n",
      "- The other approach is to create a binary array representing the entire trial and then using this array to index. This is typically faster, but may be relatively demanding in terms of memory\n",
      "\n",
      "Let's start with the first approach. \n",
      "\n",
      "We begin by introducing yet another piece of python magic, the [`enumerate`](http://docs.python.org/2/library/functions.html#enumerate) function. This function is used to iterate over a sequence, while also keeping track of your place in the sequence. \n",
      "\n",
      "                                                                         \n",
      "For example, let's consider the following sequence: \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = [x**2 for x in range(10)]\n",
      "print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's `enumerate` this sequence. In each iteration through the loop, we get the value of the current item in our sequence and also the index of that item. For example: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, n in enumerate(a):\n",
      "    print i, n\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is equivalent to something like: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(a)):\n",
      "    print i, a[i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### But you have to admit it's more elegant!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sta1(spike_times, time_arr, stim_arr, num_bins=200): \n",
      "    \"\"\" \n",
      "    Calculate the STA by looping over the spikes\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    spike_times : 1d array\n",
      "        Times of occurence of action potentials (micro-seconds)\n",
      "    \n",
      "    time_arr : 1d array \n",
      "        The time-bins in the stimulus presentation\n",
      "    \n",
      "    stim_arr : 1d array\n",
      "        The stimulus values (in dB) at each time bin\n",
      "    \n",
      "    num_bins : int\n",
      "        The number of time-bins to calculate the STA for. \n",
      "\n",
      "    Return \n",
      "    ------\n",
      "    STA : 1d array\n",
      "        The spike-triggered average stimulus \n",
      "\n",
      "    \"\"\"\n",
      "    result = []\n",
      "    # We enumerate the spike times:\n",
      "    for spike_idx, time in enumerate(spike_times):\n",
      "        idx = np.where(time_arr == time)[0]\n",
      "        result.append(stim_arr[idx-num_bins:idx])\n",
      "    return np.mean(result, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Can you see any salient problems with what we wrote above? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est_sta1 = sta1(spikes, rec_arr['time'], volt2dB(rec_arr['volt'], header['intensity (dB)']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's cryptic! What just happened?\n",
      "\n",
      "\n",
      "Let's fix it:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sta1(spike_times, time_arr, stim_arr, num_bins=200): \n",
      "    \"\"\" \n",
      "    Calculate the STA by looping over the spikes\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    spike_times : 1d array\n",
      "        Times of occurence of action potentials (micro-seconds)\n",
      "    \n",
      "    time_arr : 1d array \n",
      "        The time-bins in the stimulus presentation\n",
      "    \n",
      "    stim_arr : 1d array\n",
      "        The stimulus values (in dB) at each time bin\n",
      "    \n",
      "    num_bins : int\n",
      "        The number of time-bins to calculate the STA for. \n",
      "\n",
      "    Return \n",
      "    ------\n",
      "    STA : 1d array\n",
      "        The spike-triggered average stimulus \n",
      "\n",
      "    \"\"\"\n",
      "    result = []\n",
      "    # We enumerate the spike times:\n",
      "    for spike_idx, time in enumerate(spike_times):\n",
      "        idx = np.where(time_arr == time)[0]\n",
      "        # Only use spikes with sufficient 'history':\n",
      "        if (idx - num_bins) > 0:\n",
      "            result.append(stim_arr[idx-num_bins:idx])\n",
      "    return np.mean(result, 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est_sta1 = sta1(spikes, rec_arr['time'], volt2dB(rec_arr['volt'], header['intensity (dB)']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(1)\n",
      "ax.plot(est_sta1)\n",
      "ax.set_xlabel('Time (before spike)')\n",
      "ax.set_ylabel('Amplitude (dB)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's pretty! The other approach is to use a big binary representation of the trial"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sta2(spike_times, time_arr, stim_arr, num_bins=200):\n",
      "    \"\"\" \n",
      "    Calculate the STA by allocating a binary array\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    spike_times : 1d array\n",
      "        Times of occurence of action potentials (micro-seconds)\n",
      "    \n",
      "    time_arr : 1d array \n",
      "        The time-bins in the stimulus presentation\n",
      "    \n",
      "    stim_arr : 1d array\n",
      "        The stimulus values (in dB) at each time bin\n",
      "    \n",
      "    num_bins : int\n",
      "        The number of time-bins to calculate the STA for. \n",
      "\n",
      "    Return \n",
      "    ------\n",
      "    STA : 1d array\n",
      "        The spike-triggered average stimulus \n",
      "\n",
      "    \"\"\"\n",
      "    raster = np.zeros(time_arr.shape)\n",
      "    spike_idx = spike_times/time_arr[1] # This is a trick: the second bin is the first non-zero bin!\n",
      "    # Indice arrays need  to be integers:\n",
      "    spike_idx = spike_idx.astype(int)\n",
      "    raster[spike_idx] = 1\n",
      "    idx = np.where(raster==1)\n",
      "    idx_w_len = np.array([idx[0] - count for count in range(num_bins, 0, -1)])\n",
      "    return np.mean(stim_arr[idx_w_len], 1)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "est_sta2 = sta2(spikes, rec_arr['time'], volt2dB(rec_arr['volt'], header['intensity (dB)']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(1)\n",
      "ax.plot(est_sta2)\n",
      "ax.set_xlabel('Time (before spike)')\n",
      "ax.set_ylabel('Amplitude (dB)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Is it worth it?\n",
      "\n",
      "One way to assess this is by *profiling* them. That is, comparing the relative timing of these two functions. The `IPython` magic function `timeit` can help us measure that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sta2(spikes, rec_arr['time'], volt2dB(rec_arr['volt'], header['intensity (dB)']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sta1(spikes, rec_arr['time'], volt2dB(rec_arr['volt'], header['intensity (dB)']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Depending on how many files you have a roughly 2 orders of magnitude speed-up can start adding up...\n",
      "\n",
      "## Interim conclusion : if you can avoid loops, do it! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## One of our implementations is clearly easier to understand. How would you go about making sure that the other one gives the right answer (except by plotting?)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Let's recap again: \n",
      "\n",
      "- We've generated functions to read the data from the data-files (using `file`, `np.loadtxt` and `mlab.csv2rec`)\n",
      "- We've generated functions to calculate the STA from the data. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Questions on any of this?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise: \n",
      "\n",
      "- Write a set of functions that calculate both STA and STV (variance!). Try to stick to DRY : \"Don't repeat yourself\"\n",
      "- Using the `axis` fill_between method, plot the STA with STV error bars."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Next, let's see how we can use what we've learned here to scale up"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}